# Gemma-3N Models for Roadtrip-Copilot

## Models

### gemma-3n-e2b (2GB)
- Efficient model for standard on-device inference
- Optimized for mobile deployment
- Fast response times (<350ms)
- Lower memory footprint

### gemma-3n-e4b (3GB) 
- Advanced model for premium features
- Higher quality responses
- Better context understanding
- Enhanced POI discovery capabilities

## Usage

These models are automatically converted and optimized by the platform-specific scripts:
- iOS: `/models/conversion/convert_gemma3n_ios.py`
- Android: `/models/conversion/convert_gemma3n_android.py`

## Note

Currently using Gemma-2 models as placeholders until Gemma-3N models are available.
The architecture and optimization pipelines are designed for seamless migration.
